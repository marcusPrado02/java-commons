# Guia: Messaging Patterns

## Vis√£o Geral

Guia completo de padr√µes de mensageria para arquiteturas event-driven com Kafka, RabbitMQ e Azure Service Bus.

---

## üéØ Quando Usar Mensageria

### Use Cases

‚úÖ **Comunica√ß√£o Ass√≠ncrona** - Desacoplar servi√ßos  
‚úÖ **Event-Driven Architecture** - Reagir a eventos de dom√≠nio  
‚úÖ **Load Leveling** - Absorver picos de carga  
‚úÖ **Fan-out** - Um evento, m√∫ltiplos consumers  
‚úÖ **Saga Pattern** - Transa√ß√µes distribu√≠das  

‚ùå **Request-Response S√≠ncrono** - Use REST/gRPC  
‚ùå **Queries** - Use APIs diretas  
‚ùå **Dados em tempo real** - Considere WebSockets  

---

## üì® Message Types

### 1. Events

Fatos que aconteceram no passado.

```java
public record OrderCreated(
    String eventId,
    String orderId,
    String customerId,
    BigDecimal totalAmount,
    Instant occurredAt
) implements DomainEvent {
    
    @Override
    public String eventType() {
        return "OrderCreated";
    }
}

// Publica√ß√£o
publisher.publish(Message.builder()
    .topic("orders.events")
    .key(order.id().value())
    .payload(new OrderCreated(...))
    .build());
```

### 2. Commands

A√ß√µes a serem executadas.

```java
public record ProcessPayment(
    String commandId,
    String orderId,
    BigDecimal amount,
    String paymentMethod
) {
    public String commandType() {
        return "ProcessPayment";
    }
}

// Publica√ß√£o
publisher.publish(Message.builder()
    .topic("payment.commands")
    .key(command.orderId())
    .payload(command)
    .build());
```

### 3. Queries

Requisi√ß√µes de dados (menos comum).

```java
public record GetOrderDetails(
    String queryId,
    String orderId,
    String replyTo
) {}
```

---

## üîÑ Message Patterns

### 1. Fire-and-Forget

Publica e esquece.

```java
@Service
public class NotificationService {
    
    private final MessagePublisher publisher;
    
    public void sendWelcomeEmail(User user) {
        publisher.publish(Message.builder()
            .topic("notifications.email")
            .key(user.id().value())
            .payload(new SendEmailCommand(
                user.email(),
                "Welcome!",
                "Welcome to our platform"
            ))
            .build());
        
        // N√£o espera resposta
    }
}
```

### 2. Request-Reply

```java
@Service
public class OrderQueryService {
    
    private final MessagePublisher publisher;
    private final Map<String, CompletableFuture<OrderDetails>> pendingQueries = 
        new ConcurrentHashMap<>();
    
    public CompletableFuture<OrderDetails> getOrderDetails(OrderId orderId) {
        String queryId = UUID.randomUUID().toString();
        String replyTopic = "order-queries-replies." + queryId;
        
        CompletableFuture<OrderDetails> future = new CompletableFuture<>();
        pendingQueries.put(queryId, future);
        
        // Publica query
        publisher.publish(Message.builder()
            .topic("order.queries")
            .key(orderId.value())
            .payload(new GetOrderDetails(queryId, orderId.value(), replyTopic))
            .build());
        
        return future.orTimeout(5, TimeUnit.SECONDS);
    }
    
    @KafkaListener(topics = "order-queries-replies.#{T(java.util.UUID).randomUUID()}")
    public void handleReply(String replyJson) {
        OrderDetails details = deserialize(replyJson);
        
        CompletableFuture<OrderDetails> future = pendingQueries.remove(details.queryId());
        if (future != null) {
            future.complete(details);
        }
    }
}
```

### 3. Pub/Sub (Fan-out)

Um evento, m√∫ltiplos consumers.

```java
// Publisher
publisher.publish(Message.builder()
    .topic("orders.created")
    .key(order.id().value())
    .payload(new OrderCreated(...))
    .build());

// Consumer 1: Inventory
@KafkaListener(topics = "orders.created", groupId = "inventory-service")
public void handleOrderCreated(OrderCreated event) {
    inventoryService.reserveStock(event);
}

// Consumer 2: Email
@KafkaListener(topics = "orders.created", groupId = "email-service")
public void handleOrderCreated(OrderCreated event) {
    emailService.sendConfirmation(event);
}

// Consumer 3: Analytics
@KafkaListener(topics = "orders.created", groupId = "analytics-service")
public void handleOrderCreated(OrderCreated event) {
    analyticsService.trackOrder(event);
}
```

### 4. Competing Consumers

M√∫ltiplas inst√¢ncias do mesmo consumer (load balancing).

```java
// Inst√¢ncia 1
@KafkaListener(topics = "order.processing", groupId = "order-processor")
public void process(OrderCommand command) {
    // Processa
}

// Inst√¢ncia 2 (mesma aplica√ß√£o, outro pod)
@KafkaListener(topics = "order.processing", groupId = "order-processor")
public void process(OrderCommand command) {
    // Processa
}

// Kafka distribui mensagens entre as inst√¢ncias
```

---

## üîê Message Guarantees

### At-Most-Once

Mensagem pode ser perdida, nunca duplicada.

```java
@KafkaListener(topics = "logs", groupId = "logger")
public void handleLog(LogMessage log) {
    logger.info(log.message());
    // N√£o faz commit - pode perder mensagens
}
```

### At-Least-Once

Mensagem nunca √© perdida, pode ser duplicada.

```java
@KafkaListener(topics = "orders.created")
public void handleOrderCreated(OrderCreated event) {
    try {
        processOrder(event);
        // Commit autom√°tico ap√≥s sucesso
    } catch (Exception e) {
        // Requeue - pode processar duplicado
        throw e;
    }
}
```

### Exactly-Once

Mensagem processada exatamente uma vez (requer idempot√™ncia).

```java
@KafkaListener(topics = "payments.process")
@Transactional
public void processPayment(ProcessPaymentCommand command) {
    // 1. Verifica idempot√™ncia
    if (processedCommands.exists(command.commandId())) {
        return;  // J√° processado
    }
    
    // 2. Processa
    paymentService.process(command);
    
    // 3. Marca como processado (mesma transa√ß√£o)
    processedCommands.save(command.commandId());
    
    // Commit transacional: Kafka offset + DB transaction
}
```

---

## üìä Kafka Patterns

### 1. Partitioning Strategy

```java
// Por aggregate ID (garante ordem)
publisher.publish(Message.builder()
    .topic("orders.events")
    .key(order.id().value())  // ‚úÖ Mesma key = mesma parti√ß√£o
    .payload(event)
    .build());

// Por tenant ID (isolamento)
publisher.publish(Message.builder()
    .topic("users.events")
    .key(user.tenantId().value())  // ‚úÖ Mensagens do mesmo tenant na mesma parti√ß√£o
    .payload(event)
    .build());
```

### 2. Compaction

```java
// Topics com compaction (√∫ltimo estado)
@Configuration
public class KafkaTopicConfig {
    
    @Bean
    public NewTopic userStateTopic() {
        return TopicBuilder.name("user.state")
            .partitions(10)
            .replicas(3)
            .config(TopicConfig.CLEANUP_POLICY_CONFIG, "compact")  // ‚úÖ Compaction
            .build();
    }
}
```

### 3. Dead Letter Queue

```java
@KafkaListener(topics = "orders.process")
public void processOrder(OrderCommand command) {
    try {
        orderService.process(command);
    } catch (Exception e) {
        log.error("Failed to process order, sending to DLQ", e);
        
        publisher.publish(Message.builder()
            .topic("orders.process.dlq")  // Dead Letter Queue
            .key(command.orderId())
            .payload(command)
            .header("error", e.getMessage())
            .header("original-topic", "orders.process")
            .build());
    }
}
```

---

## üê∞ RabbitMQ Patterns

### 1. Work Queue

```java
// Publisher
channel.basicPublish(
    "",                   // default exchange
    "work.queue",         // queue name
    MessageProperties.PERSISTENT_TEXT_PLAIN,
    message.getBytes()
);

// Consumer (competing)
@RabbitListener(queues = "work.queue")
public void processWork(String message) {
    // Processa
}
```

### 2. Topic Exchange

```java
// Publisher
publisher.publish(Message.builder()
    .exchange("events")
    .routingKey("order.created.premium")  // Routing key
    .payload(event)
    .build());

// Consumer 1: Todas orders
@RabbitListener(bindings = @QueueBinding(
    value = @Queue("all-orders"),
    exchange = @Exchange(value = "events", type = "topic"),
    key = "order.#"  // Wildcard
))
public void handleAllOrders(OrderEvent event) {}

// Consumer 2: Apenas premium
@RabbitListener(bindings = @QueueBinding(
    value = @Queue("premium-orders"),
    exchange = @Exchange(value = "events", type = "topic"),
    key = "order.*.premium"
))
public void handlePremiumOrders(OrderEvent event) {}
```

### 3. Priority Queue

```java
@RabbitListener(queues = "tasks", containerFactory = "priorityFactory")
public void processTask(Task task) {
    // Tarefas com maior prioridade primeiro
}

// Publica√ß√£o
channel.basicPublish(
    "",
    "tasks",
    new AMQP.BasicProperties.Builder()
        .priority(9)  // 0-9, maior = mais priorit√°rio
        .build(),
    message.getBytes()
);
```

---

## ‚ö° Performance Patterns

### 1. Batching

```java
@Service
public class BatchedMessagePublisher {
    
    private final List<Message> batch = new ArrayList<>();
    private final int batchSize = 100;
    
    public synchronized void publish(Message message) {
        batch.add(message);
        
        if (batch.size() >= batchSize) {
            flush();
        }
    }
    
    private void flush() {
        if (batch.isEmpty()) return;
        
        kafkaTemplate.send(batch);
        batch.clear();
    }
    
    @Scheduled(fixedDelay = 1000)
    public void flushPeriodically() {
        flush();
    }
}
```

### 2. Parallel Processing

```java
@KafkaListener(
    topics = "orders.process",
    concurrency = "10"  // 10 consumer threads
)
public void processOrder(OrderCommand command) {
    orderService.process(command);
}
```

### 3. Buffering

```java
@Component
public class BufferedConsumer {
    
    private final BlockingQueue<Message> buffer = new LinkedBlockingQueue<>(10000);
    
    @KafkaListener(topics = "events")
    public void receive(Message message) {
        buffer.offer(message);  // Non-blocking
    }
    
    @Scheduled(fixedDelay = 100)
    public void processBuffer() {
        List<Message> messages = new ArrayList<>();
        buffer.drainTo(messages, 100);  // Processa at√© 100 por vez
        
        messages.parallelStream().forEach(this::process);
    }
}
```

---

## Best Practices

### ‚úÖ DO

```java
// ‚úÖ Use idempotency keys
message.header("idempotency-key", UUID.randomUUID().toString());

// ‚úÖ Propague correlation ID
message.header("correlation-id", RequestContext.getCorrelationId());

// ‚úÖ Versione schemas
message.header("schema-version", "v2");

// ‚úÖ Implemente retry com backoff
@RetryableTopic(
    attempts = "3",
    backoff = @Backoff(delay = 1000, multiplier = 2.0)
)

// ‚úÖ Monitore lag
metrics.recordGauge("kafka.consumer.lag", consumerLag);
```

### ‚ùå DON'T

```java
// ‚ùå N√ÉO bloqueie consumer threads
@KafkaListener
public void handle(Message msg) {
    Thread.sleep(10000);  // ‚ùå
}

// ‚ùå N√ÉO perca correlation ID
// ‚ùå N√ÉO ignore dead letter queues
// ‚ùå N√ÉO use mensageria para queries s√≠ncronas
```

---

## Ver Tamb√©m

- [Domain Events](domain-events.md)
- [Transactional Outbox](../api-reference/app-outbox.md)
- [Kafka Adapter](../api-reference/adapters/messaging-kafka.md)
- [Observability](observability.md)
